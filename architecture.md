# System Architecture

High-level overview of the Crypto News Agent's technical design and data flows.

---

## System Overview

```mermaid
flowchart LR
    USER[ðŸ‘¤ User] --> REACT[âš›ï¸ React]
    REACT --> API[ðŸš€ FastAPI]
    API --> SEARCH[(ðŸ” Search)]
    API --> LLM[ðŸ¤– LLM]

    CRON[â° Cron] --> SCRAPER[ðŸ•·ï¸ Scraper]
    SCRAPER --> DB[(ðŸ’¾ SQLite)]
    DB --> SEARCH

    LLM -.->|SSE Stream| REACT
```

**Two Pipelines:**

1. **Background**: Cron â†’ Scraper â†’ Database â†’ Search Indexes
2. **Real-time**: User â†’ Query â†’ Search â†’ LLM â†’ Streaming Response

---

## Data Ingestion (Background)

```mermaid
flowchart TB
    CRON[â° Cron Job] --> SCRAPER[ðŸ•·ï¸ Scraper]

    subgraph "Sources"
        CT[CoinTelegraph]
        TD[The Defiant]
        DL[DL News]
    end

    SCRAPER --> CT & TD & DL
    CT & TD & DL --> DB[(ðŸ’¾ SQLite)]
    DB --> EMBED[ðŸ§  Embeddings]
    EMBED --> QDRANT[(Qdrant)]
```

**Components:**

- **Cron**: Configurable scheduling (1min/5min/hourly/daily)
- **Scraper**: `httpx` + `BeautifulSoup` with User-Agent headers, parallel fetching
- **Database**: SQLite with article metadata (title, content, URL, dates)
- **Embeddings**: `all-MiniLM-L6-v2` (384-dim vectors, ~50MB model)
- **Qdrant**: Vector similarity search

---

## User Query Flow (Real-time)

```mermaid
flowchart TB
    USER[ðŸ‘¤ Query] --> API[ðŸš€ FastAPI]
    API --> MOD[ðŸ›¡ï¸ Moderation]
    MOD --> SEARCH[ðŸ”Ž Search]
    SEARCH --> QDRANT & DB
    SEARCH --> LLM[ðŸ¤– LLM]
    LLM --> OLLAMA[Ollama] & OPENAI[OpenAI]
    LLM -.->|SSE| USER
```

**Pipeline Steps:**

1. **Moderation**: Transformers pipeline (unitary/toxic-bert) checks for toxic/inappropriate content (threshold: 0.5)
2. **Search**:
   - Generate query embedding (384-dim)
   - Qdrant semantic search
   - Filter by date, return top-K
3. **LLM Context**: Build prompt with retrieved articles + chat history
4. **Stream Response**: Token-by-token via Server-Sent Events

---

## Tech Stack

| Layer          | Technology                                 |
| -------------- | ------------------------------------------ |
| **Frontend**   | React 18, Vite, Server-Sent Events         |
| **Backend**    | FastAPI, SQLAlchemy, LangChain             |
| **Search**     | Qdrant (semantic)                          |
| **Embeddings** | sentence-transformers (all-MiniLM-L6-v2)   |
| **LLM**        | Ollama (local) or OpenAI (cloud)           |
| **Moderation** | transformers pipeline (unitary/toxic-bert) |
| **Scraping**   | httpx, BeautifulSoup                       |
| **Database**   | SQLite                                     |
| **Scheduling** | Cron                                       |

---

## Key Features

### Dynamic Index Reloading

- **Problem**: Cron updates indexes while server runs
- **Solution**: Check file modification times before each search
- **Benefit**: No server restart needed for new articles

### LLM Provider Auto-Detection

1. Check if Ollama running (GET `http://localhost:11434/api/tags`)
2. If yes â†’ use Ollama (free, local)
3. If no â†’ check for OpenAI API key
4. If yes â†’ use OpenAI (paid, cloud)
5. If neither â†’ error with setup instructions

### Session Management

- **Storage**: In-memory dictionary (MVP)
- **TTL**: 60 minutes auto-expiration
- **Purpose**: Chat history for contextual follow-up questions
- **Header**: `X-Session-Id` for session tracking

---

## Data Flow Example

**Query:** "What's the latest Bitcoin news?"

1. React sends `POST /api/ask` with session ID
2. FastAPI checks session for chat history
3. Moderation validates query (passes âœ“)
4. Search service:
   - Checks if indexes updated (auto-reload if needed)
   - Generates query embedding
   - Qdrant returns candidates with similarity scores
   - Filters last 30 days, returns top 5
5. LLM builds context with articles + chat history
6. Streams tokens via SSE:
   ```
   data: {"sources": [...]}
   data: {"content": "According to"}
   data: {"content": " [Article 1]"}
   data: [DONE]
   ```
7. React displays sources + streaming response
8. Session stores conversation for follow-ups

---

## Architecture Decisions

See [reflection.md](./reflection.md) for detailed discussion of MVP choices, trade-offs, and future improvements.
